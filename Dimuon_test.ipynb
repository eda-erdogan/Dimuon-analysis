{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13651/3733293531.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    }
   ],
   "source": [
    "# Load CSV file including 100k events\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('/home/edaerdogan/Desktop/dimuonai/dimuon.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering and labeling \n",
    "signal_df = df[df['Q1'] * df['Q2'] < 0].copy()\n",
    "background_df = df[df['Q1'] * df['Q2'] >= 0].copy() \n",
    "\n",
    "signal_df['target'] = 0\n",
    "background_df['target'] = 1\n",
    "\n",
    "filtered_df = pd.concat([signal_df, background_df], ignore_index=True)\n",
    "features = filtered_df[['pt1', 'pt2', 'eta1', 'eta2', 'phi1', 'phi2', 'Q1', 'Q2']] #Since M is given as a parameter for both the muons, it is not taken as a parameter\n",
    "target = filtered_df['target']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_target, test_target = train_test_split(features, target, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Signal Events: 62214\n",
      "Total Background Events: 37786\n",
      "Signal Percentage: 62.214000000000006%\n",
      "Background Percentage: 37.785999999999994%\n"
     ]
    }
   ],
   "source": [
    "signal_count = len(df[df['Q1'] * df['Q2'] < 0])\n",
    "background_count = len(df[df['Q1'] * df['Q2'] >= 0])\n",
    "\n",
    "total_signal = signal_count\n",
    "total_background = background_count\n",
    "total_events = total_signal + total_background\n",
    "\n",
    "# Calculate percentages\n",
    "signal_percentage = total_signal / total_events * 100\n",
    "background_percentage = total_background / total_events * 100\n",
    "\n",
    "print(f'Total Signal Events: {total_signal}')\n",
    "print(f'Total Background Events: {total_background}')\n",
    "print(f'Signal Percentage: {signal_percentage}%')\n",
    "print(f'Background Percentage: {background_percentage}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = filtered_df[['pt1', 'pt2', 'eta1', 'eta2', 'phi1', 'phi2', 'Q1', 'Q2']]\n",
    "target = filtered_df['target']\n",
    "\n",
    "X = features.to_numpy(dtype='float')\n",
    "Y = target.to_numpy(dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.2360,  2.3905, -0.5848,  ..., -2.2764, -1.0000,  1.0000],\n",
      "        [ 8.9484,  6.7821, -1.3530,  ..., -0.3814, -1.0000,  1.0000],\n",
      "        [ 4.0910,  4.8186,  1.2463,  ...,  2.2493, -1.0000,  1.0000],\n",
      "        ...,\n",
      "        [11.4290,  1.1869,  1.8963,  ..., -1.6911, -1.0000, -1.0000],\n",
      "        [ 9.4401,  2.8993,  1.3652,  ..., -0.5243,  1.0000,  1.0000],\n",
      "        [ 3.3954, 12.6496,  2.3445,  ..., -1.8854,  1.0000,  1.0000]])\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(Y, dtype=torch.float32).reshape(-1, 1)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=8, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=50, out_features=20, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=20, out_features=1, bias=True)\n",
      "  (7): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, latest loss 0.0002693688729777932\n",
      "Finished epoch 1, latest loss 0.0006065780180506408\n",
      "Finished epoch 2, latest loss 2.141408003808465e-05\n",
      "Finished epoch 3, latest loss 1.4741329323442187e-05\n",
      "Finished epoch 4, latest loss 1.323141623288393e-05\n",
      "Finished epoch 5, latest loss 0.0014532123459503055\n",
      "Finished epoch 6, latest loss 3.9804373955121264e-05\n",
      "Finished epoch 7, latest loss 0.0015726550482213497\n",
      "Finished epoch 8, latest loss 0.0008910330361686647\n",
      "Finished epoch 9, latest loss 6.592884165002033e-05\n",
      "Finished epoch 10, latest loss 0.00011740001355065033\n",
      "Finished epoch 11, latest loss 0.00024978184956125915\n",
      "Finished epoch 12, latest loss 9.714773477753624e-05\n",
      "Finished epoch 13, latest loss 5.18995730089955e-05\n",
      "Finished epoch 14, latest loss 3.1773852242622524e-05\n",
      "Finished epoch 15, latest loss 5.7518877838447224e-06\n",
      "Finished epoch 16, latest loss 1.0058285937475375e-07\n",
      "Finished epoch 17, latest loss 3.645959077402949e-05\n",
      "Finished epoch 18, latest loss 2.059011603705585e-05\n",
      "Finished epoch 19, latest loss 8.318665095430333e-06\n",
      "Accuracy 0.9998300075531006\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "# define the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "loss_fn   = nn.BCELoss()  # binary cross entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) #lr değiştirrilebilir mi \n",
    " \n",
    "n_epochs = 20 #e:15 b:32 accuracy: 0.377, e:15 b:64 a:0.377, e:15 b:128 a:0.377, e:30, b:128 a:0.97; e:20 b:128 a:0.99(best result) (20-80 included)\n",
    "batch_size = 128\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = x[i:i+batch_size]\n",
    "        y_pred = model(Xbatch)\n",
    "        ybatch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')\n",
    " \n",
    "# compute accuracy (no_grad is optional)\n",
    "with torch.no_grad():\n",
    "    y_pred = model(x)\n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

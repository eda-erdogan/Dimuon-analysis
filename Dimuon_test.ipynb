{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    }
   ],
   "source": [
    "# Load CSV file including 100k events\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('/home/edaerdogan/Desktop/dimuonai/dimuon.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering and labeling \n",
    "signal_df = df[df['Q1'] * df['Q2'] < 0].copy()\n",
    "background_df = df[df['Q1'] * df['Q2'] >= 0].copy() \n",
    "\n",
    "signal_df['target'] = 0\n",
    "background_df['target'] = 1\n",
    "\n",
    "filtered_df = pd.concat([signal_df, background_df], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Signal Events: 62214\n",
      "Total Background Events: 37786\n",
      "Signal Percentage: 62.214000000000006%\n",
      "Background Percentage: 37.785999999999994%\n"
     ]
    }
   ],
   "source": [
    "signal_count = len(df[df['Q1'] * df['Q2'] < 0])\n",
    "background_count = len(df[df['Q1'] * df['Q2'] >= 0])\n",
    "\n",
    "total_signal = signal_count\n",
    "total_background = background_count\n",
    "total_events = total_signal + total_background\n",
    "\n",
    "# Calculate percentages\n",
    "signal_percentage = total_signal / total_events * 100\n",
    "background_percentage = total_background / total_events * 100\n",
    "\n",
    "print(f'Total Signal Events: {total_signal}')\n",
    "print(f'Total Background Events: {total_background}')\n",
    "print(f'Signal Percentage: {signal_percentage}%')\n",
    "print(f'Background Percentage: {background_percentage}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = filtered_df[['pt1', 'pt2', 'eta1', 'eta2', 'phi1', 'phi2', 'Q1', 'Q2']]\n",
    "target = filtered_df['target']\n",
    "\n",
    "X = features.to_numpy(dtype='float')\n",
    "Y = target.to_numpy(dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.2360,  2.3905, -0.5848,  ..., -2.2764, -1.0000,  1.0000],\n",
      "        [ 8.9484,  6.7821, -1.3530,  ..., -0.3814, -1.0000,  1.0000],\n",
      "        [ 4.0910,  4.8186,  1.2463,  ...,  2.2493, -1.0000,  1.0000],\n",
      "        ...,\n",
      "        [11.4290,  1.1869,  1.8963,  ..., -1.6911, -1.0000, -1.0000],\n",
      "        [ 9.4401,  2.8993,  1.3652,  ..., -0.5243,  1.0000,  1.0000],\n",
      "        [ 3.3954, 12.6496,  2.3445,  ..., -1.8854,  1.0000,  1.0000]])\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(Y, dtype=torch.float32).reshape(-1, 1)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=8, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=50, out_features=20, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=20, out_features=1, bias=True)\n",
      "  (7): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, latest loss 4.1806888475548476e-05\n",
      "Finished epoch 1, latest loss 0.0005317169707268476\n",
      "Finished epoch 2, latest loss 8.621768211014569e-05\n",
      "Finished epoch 3, latest loss 0.003441666718572378\n",
      "Finished epoch 4, latest loss 3.7849276850465685e-06\n",
      "Finished epoch 5, latest loss 0.0004483017837628722\n",
      "Finished epoch 6, latest loss 0.002661291277036071\n",
      "Finished epoch 7, latest loss 5.1632290706038475e-05\n",
      "Finished epoch 8, latest loss 6.906952330609784e-05\n",
      "Finished epoch 9, latest loss 0.00010955195466522127\n",
      "Finished epoch 10, latest loss 0.00041529370355419815\n",
      "Finished epoch 11, latest loss 0.00023112961207516491\n",
      "Finished epoch 12, latest loss 4.291659024602268e-06\n",
      "Finished epoch 13, latest loss 9.445937030250207e-05\n",
      "Finished epoch 14, latest loss 1.937151523634384e-07\n",
      "Finished epoch 15, latest loss 3.166497890561004e-07\n",
      "Finished epoch 16, latest loss 3.241004264964431e-07\n",
      "Finished epoch 17, latest loss 0.0\n",
      "Finished epoch 18, latest loss 0.0\n",
      "Finished epoch 19, latest loss 2.0444782421691343e-05\n",
      "Accuracy 0.995930016040802\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "# define the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "loss_fn   = nn.BCELoss()  # binary cross entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) #lr değiştirrilebilir mi \n",
    " \n",
    "n_epochs = 20 #e:15 b:32 accuracy: 0.377, e:15 b:64 a:0.377, e:15 b:128 a:0.377, e:30, b:128 a:0.97; e:20 b:128 a:0.99(best result)\n",
    "batch_size = 128\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = x[i:i+batch_size]\n",
    "        y_pred = model(Xbatch)\n",
    "        ybatch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')\n",
    " \n",
    "# compute accuracy (no_grad is optional)\n",
    "with torch.no_grad():\n",
    "    y_pred = model(x)\n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
